{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "precise-lingerie",
   "metadata": {},
   "source": [
    "<h2>Predicting Fuel Efficiency of Vehicles - Part 3 </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-strike",
   "metadata": {},
   "source": [
    "<h3>Selecting and Training Models</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-window",
   "metadata": {},
   "source": [
    "1. Select and Train a few Algorithms(Linear Regression, Decision Tree, RandomForest)\n",
    "2. Evaluation using Mean Squared Error\n",
    "3. Model Evaluation using Cross Validation\n",
    "4. Hyperparameter Tuning using GridSearchCV\n",
    "5. Check Feature Importance\n",
    "6. Evaluate the Final System on test data\n",
    "7. Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interim-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing a few general use case libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secure-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the .data file using pandas\n",
    "\n",
    "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.data', names=cols, na_values = \"?\",\n",
    "                comment = '\\t',\n",
    "                sep= \" \",\n",
    "                skipinitialspace=True)\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"Cylinders\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exterior-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>4668.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>6</td>\n",
       "      <td>146.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
       "145          4          83.0        61.0  2003.0          19.0          74   \n",
       "151          4          79.0        67.0  2000.0          16.0          74   \n",
       "388          4         156.0        92.0  2585.0          14.5          82   \n",
       "48           6         250.0        88.0  3139.0          14.5          71   \n",
       "114          4          98.0        90.0  2265.0          15.5          73   \n",
       "..         ...           ...         ...     ...           ...         ...   \n",
       "147          4          90.0        75.0  2108.0          15.5          74   \n",
       "156          8         400.0       170.0  4668.0          11.5          75   \n",
       "395          4         135.0        84.0  2295.0          11.6          82   \n",
       "14           4         113.0        95.0  2372.0          15.0          70   \n",
       "362          6         146.0       120.0  2930.0          13.8          81   \n",
       "\n",
       "     Origin  \n",
       "145       3  \n",
       "151       2  \n",
       "388       1  \n",
       "48        1  \n",
       "114       2  \n",
       "..      ...  \n",
       "147       2  \n",
       "156       1  \n",
       "395       1  \n",
       "14        3  \n",
       "362       3  \n",
       "\n",
       "[318 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##segregate the feature and target variable\n",
    "data = strat_train_set.drop(\"MPG\", axis=1)\n",
    "data_labels = strat_train_set[\"MPG\"].copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "##preprocess the Origin column in data  \n",
    "def preprocess_origin_cols(df):\n",
    "    df[\"Origin\"] = df[\"Origin\"].map({1: \"India\", 2: \"USA\", 3: \"Germany\"})  #renaming 1, 2, 3 for India, USA, Germany\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medieval-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating custom attribute adder class  (It works the same way like part 2)\n",
    "acc_ix, hpower_ix, cyl_ix = 4,2, 0\n",
    "\n",
    "class CustomAttrAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, acc_on_power=True): # no *args or **kargs\n",
    "        self.acc_on_power = acc_on_power\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        acc_on_cyl = X[:, acc_ix] / X[:, cyl_ix]\n",
    "        if self.acc_on_power:\n",
    "            acc_on_power = X[:, acc_ix] / X[:, hpower_ix]\n",
    "            return np.c_[X, acc_on_power, acc_on_cyl]\n",
    "        \n",
    "        return np.c_[X, acc_on_cyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electoral-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_pipeline_transformer(data):\n",
    "    '''\n",
    "    Function to process numerical transformations\n",
    "    Argument:\n",
    "        data: original dataframe \n",
    "    Returns:\n",
    "        num_attrs: numerical dataframe\n",
    "        num_pipeline: numerical pipeline object\n",
    "        \n",
    "    '''\n",
    "    numerics = ['float64', 'int64']\n",
    "\n",
    "    num_attrs = data.select_dtypes(include=numerics)\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attrs_adder', CustomAttrAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "    return num_attrs, num_pipeline\n",
    "\n",
    "\n",
    "def pipeline_transformer(data):\n",
    "    '''\n",
    "    Complete transformation pipeline for both\n",
    "    nuerical and categorical data.\n",
    "    \n",
    "    Argument:\n",
    "        data: original dataframe \n",
    "    Returns:\n",
    "        prepared_data: transformed data, ready to use\n",
    "    '''\n",
    "    cat_attrs = [\"Origin\"]\n",
    "    num_attrs, num_pipeline = num_pipeline_transformer(data)\n",
    "    #print(list(num_attrs)) I can delete this\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, list(num_attrs)),\n",
    "        (\"cat\", OneHotEncoder(), cat_attrs),\n",
    "        ])\n",
    "    prepared_data = full_pipeline.fit_transform(data)\n",
    "    return prepared_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-matter",
   "metadata": {},
   "source": [
    "<h3>From raw data to processed data in 2 steps</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quick-intensity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85657842, -1.07804475, -1.15192977, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.85657842, -1.1174582 , -0.9900351 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.85657842, -0.3587492 , -0.31547399, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.85657842, -0.56566984, -0.53133355, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.85657842, -0.78244384, -0.23452666, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.32260746, -0.45728283,  0.44003446, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##from raw data to processed data in 2 steps\n",
    "preprocessed_df = preprocess_origin_cols(data)\n",
    "prepared_data = pipeline_transformer(preprocessed_df)\n",
    "prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "copyrighted-poison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.85657842, -1.07804475, -1.15192977, -1.17220298,  1.21586943,\n",
       "       -0.54436373,  1.70952741,  1.29565517,  1.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data[0]  #the first rows of the prepared data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-creek",
   "metadata": {},
   "source": [
    "<h3>Selecting and Training Models</h3>\n",
    "1. Linear Regression <br>\n",
    "2. Decision Tree <br>\n",
    "3. Random Forest <br>\n",
    "4. SVM regressor <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fewer-programmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(prepared_data, data_labels)#it gives a linear regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aboriginal-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of samples:  [29.08069379 27.78336755 26.08031176 12.70419279 22.23454159]\n"
     ]
    }
   ],
   "source": [
    "##testing the predictions\n",
    "sample_data = data.iloc[:5]  #5 rows for a sample data\n",
    "sample_labels = data_labels.iloc[:5]\n",
    "\n",
    "sample_data_prepared = pipeline_transformer(sample_data)\n",
    "\n",
    "print(\"Prediction of samples: \", lin_reg.predict(sample_data_prepared)) \n",
    "#if I want to print the name of the labels, activate #print(list(num_attrs)) in num_pipeline_transformer above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "champion-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Labels of samples:  [32.0, 31.0, 26.0, 18.0, 26.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Labels of samples: \", list(sample_labels))  #this is how linear regression perform:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-spiritual",
   "metadata": {},
   "source": [
    "<h4>Mean Squared Error</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "waiting-drinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9590402225760872"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mpg_predictions = lin_reg.predict(prepared_data)\n",
    "lin_mse = mean_squared_error(data_labels, mpg_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-estimate",
   "metadata": {},
   "source": [
    "<h3>Decision Tree</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitted-patrol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "handled-glucose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_predictions = tree_reg.predict(prepared_data)\n",
    "tree_mse = mean_squared_error(data_labels, mpg_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-seminar",
   "metadata": {},
   "source": [
    "But no model is perfect, this means that our model has overfit the data to a great extent. (the model is highly overfitting the data, it fits well the training (seen) data but it performs poorly on unseen data which is has not seen yet)\n",
    "\n",
    "We won't be touching out test data until we finalize our model. So, how do we check for what's happening?\n",
    "\n",
    "Model Evaluation using Cross Validation\n",
    "Scikit-Learnâ€™s K-fold cross-validation feature randomly splits the training set into K distinct subsets called folds, \n",
    "then it trains and evaluates the model K times, picking a different fold for evaluation every time and training on the \n",
    "other K-1 folds.\n",
    "\n",
    "The result is an array containing the K evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "surrounded-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg,   #this function will give me 10 scores\n",
    "                         prepared_data, \n",
    "                         data_labels, \n",
    "                         scoring=\"neg_mean_squared_error\",  #this is an argument (neg_mean_squared_error), it accepts an argument\n",
    "                         cv = 10) #10 cross validations or 10 folds\n",
    "tree_reg_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "second-caution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1257999 , 3.23684839, 3.08043219, 3.36841951, 2.28992358,\n",
       "       2.99134167, 3.09652022, 4.39349661, 4.12928175, 2.71602176])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg_rmse_scores  #10 scores root mean square error values for the 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "nutritional-laser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.242808558763806"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg_rmse_scores.mean()  #the mean of the 10 scores Result: 3.2428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reflected-steam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.43254597, 3.45157629, 3.6621715 , 2.59652976, 2.48023405,\n",
       "       2.74798115, 3.32524647, 2.42208917, 3.78133275, 2.8573747 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, prepared_data, data_labels, scoring=\"neg_mean_squared_error\", cv = 10)\n",
    "lin_reg_rmse_scores = np.sqrt(-scores)\n",
    "lin_reg_rmse_scores   #the same for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "congressional-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0757081793709324"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_rmse_scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-credit",
   "metadata": {},
   "source": [
    "<h3>Random Forest model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "valid-server",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5585913052822704"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(prepared_data, data_labels)\n",
    "forest_reg_cv_scores = cross_val_score(forest_reg,\n",
    "                                         prepared_data,\n",
    "                                         data_labels,\n",
    "                                         scoring='neg_mean_squared_error',\n",
    "                                         cv = 10)\n",
    "\n",
    "forest_reg_rmse_scores = np.sqrt(-forest_reg_cv_scores)\n",
    "forest_reg_rmse_scores.mean()  \n",
    "#2.558591, so far random forest es the best performer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-sigma",
   "metadata": {},
   "source": [
    "<h3>Support Vector Machine Regressor</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "suitable-arthur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.08659162080283"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel='linear')  \n",
    "svm_reg.fit(prepared_data, data_labels)\n",
    "svm_cv_scores = cross_val_score(svm_reg, prepared_data, data_labels,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                cv = 10)\n",
    "svm_rmse_scores = np.sqrt(-svm_cv_scores)\n",
    "svm_rmse_scores.mean()  #Resp.: 3.09, rforest still being the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-proposal",
   "metadata": {},
   "source": [
    "<h3>Hyperparameter Tuning using GridSearchCV</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "gentle-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV  #to fine-tune the hiperparameters of the random f.regressor. This to \n",
    "                                                  # improve the performance of r.f.model.\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True,\n",
    "                           cv=10,\n",
    "                          )\n",
    "\n",
    "grid_search.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daily-lending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 30}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "featured-significance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5715192218398215 {'max_features': 2, 'n_estimators': 3}\n",
      "3.1733763358529687 {'max_features': 2, 'n_estimators': 10}\n",
      "2.9582545279429935 {'max_features': 2, 'n_estimators': 30}\n",
      "3.2884828756823277 {'max_features': 4, 'n_estimators': 3}\n",
      "2.9157676481198873 {'max_features': 4, 'n_estimators': 10}\n",
      "2.7541346184672575 {'max_features': 4, 'n_estimators': 30}\n",
      "3.1558401868513934 {'max_features': 6, 'n_estimators': 3}\n",
      "2.818444901591381 {'max_features': 6, 'n_estimators': 10}\n",
      "2.6435815144546435 {'max_features': 6, 'n_estimators': 30}\n",
      "2.8216031890490223 {'max_features': 8, 'n_estimators': 3}\n",
      "2.7937427545550846 {'max_features': 8, 'n_estimators': 10}\n",
      "2.731538156637186 {'max_features': 8, 'n_estimators': 30}\n",
      "3.473805822892421 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "2.822809813277452 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "3.364310680886484 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "2.928852924891443 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "3.0634690881323823 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "2.8006570963563115 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "\n",
    "##printing all the parameters along with their scores\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "    #Res.: I am going to choose 2.64 (the lowest value, no 2.55 from above. This is the improved r.forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-rates",
   "metadata": {},
   "source": [
    "<h3>Checking Feature importance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "metropolitan-domestic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19300645, 0.16976561, 0.16414755, 0.26108427, 0.01822394,\n",
       "       0.12227059, 0.02604562, 0.04004234, 0.00202216, 0.00194882,\n",
       "       0.00144264])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importances \n",
    "\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances #ampliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dramatic-nylon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acc_on_power', 0.0260456199701643),\n",
       " ('acc_on_cyl', 0.04004234272187999),\n",
       " ('Weight', 0.2610842693240977),\n",
       " ('Model Year', 0.12227059426783451),\n",
       " ('Horsepower', 0.16414754588211078),\n",
       " ('Displacement', 0.1697656104126077),\n",
       " ('Cylinders', 0.19300645425296942),\n",
       " ('Acceleration', 0.018223944070466944)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attrs = [\"acc_on_power\", \"acc_on_cyl\"]\n",
    "numerics = ['float64', 'int64']\n",
    "num_attrs = list(data.select_dtypes(include=numerics))\n",
    "\n",
    "attrs = num_attrs + extra_attrs\n",
    "sorted(zip(attrs, feature_importances), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-repeat",
   "metadata": {},
   "source": [
    "<h3>Evaluating the entire system on Test Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "visible-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"MPG\", axis=1)\n",
    "y_test = strat_test_set[\"MPG\"].copy()\n",
    "\n",
    "X_test_preprocessed = preprocess_origin_cols(X_test)\n",
    "X_test_prepared = pipeline_transformer(X_test_preprocessed)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "human-friendly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.079721127346148"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse  #Resp.: 3.0797, we can iterate to improve this result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-binary",
   "metadata": {},
   "source": [
    "<h3>Creating a function to cover this entire flow</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "likely-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mpg(config, model):\n",
    "    \n",
    "    if type(config) == dict:\n",
    "        df = pd.DataFrame(config)\n",
    "    else:\n",
    "        df = config          #By default:true\n",
    "    \n",
    "    preproc_df = preprocess_origin_cols(df)\n",
    "    prepared_df = pipeline_transformer(preproc_df)\n",
    "    #print(prepared_df)\n",
    "    y_pred = model.predict(prepared_df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "accepted-prompt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.56      , 17.64666667, 21.64      ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##checking it on a random sample\n",
    "vehicle_config = {\n",
    "    'Cylinders': [4, 6, 8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin': [3, 2, 1]\n",
    "}\n",
    "\n",
    "predict_mpg(vehicle_config, final_model) \n",
    "#Res. 3 predictions for 3 rows, it should be close to what I have seen in the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-district",
   "metadata": {},
   "source": [
    "<h3>Save the Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "tested-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "prime-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the model\n",
    "with open(\"model.bin\", 'wb') as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "terminal-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.56      , 17.64666667, 21.64      ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loading the model from the saved file\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "\n",
    "predict_mpg(vehicle_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These results are the same as the predictions in 45th line because of the same vehicle configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "violent-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests   #install requests packages using cmd, pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "accurate-release",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\\n  \"http://www.w3.org/TR/html4/loose.dtd\">\\n<html>\\n  <head>\\n    <title>FileNotFoundError: [Errno 2] No such file or directory: \\'./model_files/model.bin\\' // Werkzeug Debugger</title>\\n    <link rel=\"stylesheet\" href=\"?__debugger__=yes&amp;cmd=resource&amp;f=style.css\"\\n        type=\"text/css\">\\n    <!-- We need to make sure this has a favicon so that the debugger does\\n         not by accident trigger a request to /favicon.ico which might\\n         change the application state. -->\\n    <link rel=\"shortcut icon\"\\n        href=\"?__debugger__=yes&amp;cmd=resource&amp;f=console.png\">\\n    <script src=\"?__debugger__=yes&amp;cmd=resource&amp;f=jquery.js\"></script>\\n    <script src=\"?__debugger__=yes&amp;cmd=resource&amp;f=debugger.js\"></script>\\n    <script type=\"text/javascript\">\\n      var TRACEBACK = 2617516597104,\\n          CONSOLE_MODE = false,\\n          EVALEX = true,\\n          EVALEX_TRUSTED = false,\\n          SECRET = \"0xnbYossizuAfRMqCDEB\";\\n    </script>\\n  </head>\\n  <body style=\"background-color: #fff\">\\n    <div class=\"debugger\">\\n<h1>FileNotFoundError</h1>\\n<div class=\"detail\">\\n  <p class=\"errormsg\">FileNotFoundError: [Errno 2] No such file or directory: \\'./model_files/model.bin\\'</p>\\n</div>\\n<h2 class=\"traceback\">Traceback <em>(most recent call last)</em></h2>\\n<div class=\"traceback\">\\n  \\n  <ul><li><div class=\"frame\" id=\"frame-2617516766496\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">2464</em>,\\n      in <code class=\"function\">__call__</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\">    </span>def __call__(self, environ, start_response):</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>&quot;&quot;&quot;The WSGI server calls the Flask application object as the</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>WSGI application. This calls :meth:`wsgi_app` which can be</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>wrapped to applying middleware.&quot;&quot;&quot;</pre>\\n<pre class=\"line current\"><span class=\"ws\">        </span>return self.wsgi_app(environ, start_response)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def __repr__(self):</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>return &quot;&lt;%s %r&gt;&quot; % (self.__class__.__name__, self.name)</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766544\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">2450</em>,\\n      in <code class=\"function\">wsgi_app</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>ctx.push()</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>response = self.full_dispatch_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>except Exception as e:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>error = e</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>response = self.handle_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>except:  # noqa: B001</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>error = sys.exc_info()[1]</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>raise</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>return response(environ, start_response)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>finally:</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766736\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">1867</em>,\\n      in <code class=\"function\">handle_exception</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span># if we want to repropagate the exception, we can attempt to</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span># raise it with the whole traceback in case we can do that</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span># (the function was actually called from the except part)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span># otherwise, we just raise the error again</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>if exc_value is e:</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>reraise(exc_type, exc_value, tb)</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>else:</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>raise e</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>self.log_exception((exc_type, exc_value, tb))</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>server_error = InternalServerError()</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766784\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\_compat.py\"</cite>,\\n      line <em class=\"line\">39</em>,\\n      in <code class=\"function\">reraise</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">    </span>import collections.abc as collections_abc</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\">    </span>def reraise(tp, value, tb=None):</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>if value.__traceback__ is not tb:</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>raise value.with_traceback(tb)</pre>\\n<pre class=\"line current\"><span class=\"ws\">        </span>raise value</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>implements_to_string = _identity</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\"></span>else:</pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>iterkeys = lambda d: d.iterkeys()</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766592\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">2447</em>,\\n      in <code class=\"function\">wsgi_app</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">        </span>ctx = self.request_context(environ)</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>error = None</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>ctx.push()</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>response = self.full_dispatch_request()</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>except Exception as e:</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>error = e</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>response = self.handle_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>except:  # noqa: B001</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>error = sys.exc_info()[1]</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766640\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">1952</em>,\\n      in <code class=\"function\">full_dispatch_request</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>request_started.send(self)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>rv = self.preprocess_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>if rv is None:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>rv = self.dispatch_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>except Exception as e:</pre>\\n<pre class=\"line current\"><span class=\"ws\">            </span>rv = self.handle_user_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>return self.finalize_request(rv)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def finalize_request(self, rv, from_error_handler=False):</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>&quot;&quot;&quot;Given the return value from a view function this finalizes</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>the request by converting it into a response and invoking the</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766880\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">1821</em>,\\n      in <code class=\"function\">handle_user_exception</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>return self.handle_http_exception(e)</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>handler = self._find_error_handler(e)</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>if handler is None:</pre>\\n<pre class=\"line current\"><span class=\"ws\">            </span>reraise(exc_type, exc_value, tb)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>return handler(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def handle_exception(self, e):</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>&quot;&quot;&quot;Handle an exception that did not have an error handler</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>associated with it, or that was raised from an error handler.</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766928\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\_compat.py\"</cite>,\\n      line <em class=\"line\">39</em>,\\n      in <code class=\"function\">reraise</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">    </span>import collections.abc as collections_abc</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\">    </span>def reraise(tp, value, tb=None):</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>if value.__traceback__ is not tb:</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>raise value.with_traceback(tb)</pre>\\n<pre class=\"line current\"><span class=\"ws\">        </span>raise value</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>implements_to_string = _identity</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\"></span>else:</pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>iterkeys = lambda d: d.iterkeys()</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766976\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">1950</em>,\\n      in <code class=\"function\">full_dispatch_request</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">        </span>self.try_trigger_before_first_request_functions()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>request_started.send(self)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>rv = self.preprocess_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>if rv is None:</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>rv = self.dispatch_request()</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>except Exception as e:</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>rv = self.handle_user_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>return self.finalize_request(rv)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def finalize_request(self, rv, from_error_handler=False):</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766688\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\"</cite>,\\n      line <em class=\"line\">1936</em>,\\n      in <code class=\"function\">dispatch_request</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>getattr(rule, &quot;provide_automatic_options&quot;, False)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>and req.method == &quot;OPTIONS&quot;</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>):</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>return self.make_default_options_response()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span># otherwise dispatch to the handler for that endpoint</pre>\\n<pre class=\"line current\"><span class=\"ws\">        </span>return self.view_functions[rule.endpoint](**req.view_args)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def full_dispatch_request(self):</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>&quot;&quot;&quot;Dispatches the request and on top of that performs request</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>pre and postprocessing as well as HTTP exception catching and</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>error handling.</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-2617516766832\">\\n  <h4>File <cite class=\"filename\">\"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\main.py\"</cite>,\\n      line <em class=\"line\">11</em>,\\n      in <code class=\"function\">predict</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\"></span>@app.route(\\'/\\', methods=[\\'POST\\'])</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span>def predict():</pre>\\n<pre class=\"line before\"><span class=\"ws\">    </span>vehicle_config = request.get_json()</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line current\"><span class=\"ws\">    </span>with open(\\'./model_files/model.bin\\', \\'rb\\') as f_in:</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>model = pickle.load(f_in)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>f_in.close()</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>predictions = predict_mpg(vehicle_config, model)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre></div>\\n</div>\\n</ul>\\n  <blockquote>FileNotFoundError: [Errno 2] No such file or directory: \\'./model_files/model.bin\\'</blockquote>\\n</div>\\n\\n<div class=\"plain\">\\n  <form action=\"/?__debugger__=yes&amp;cmd=paste\" method=\"post\">\\n    <p>\\n      <input type=\"hidden\" name=\"language\" value=\"pytb\">\\n      This is the Copy/Paste friendly version of the traceback.  <span\\n      class=\"pastemessage\">You can also paste this traceback into\\n      a <a href=\"https://gist.github.com/\">gist</a>:\\n      <input type=\"submit\" value=\"create paste\"></span>\\n    </p>\\n    <textarea cols=\"50\" rows=\"10\" name=\"code\" readonly>Traceback (most recent call last):\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 2464, in __call__\\n    return self.wsgi_app(environ, start_response)\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 2450, in wsgi_app\\n    response = self.handle_exception(e)\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1867, in handle_exception\\n    reraise(exc_type, exc_value, tb)\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\_compat.py&quot;, line 39, in reraise\\n    raise value\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 2447, in wsgi_app\\n    response = self.full_dispatch_request()\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1952, in full_dispatch_request\\n    rv = self.handle_user_exception(e)\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1821, in handle_user_exception\\n    reraise(exc_type, exc_value, tb)\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\_compat.py&quot;, line 39, in reraise\\n    raise value\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1950, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1936, in dispatch_request\\n    return self.view_functions[rule.endpoint](**req.view_args)\\n  File &quot;C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\main.py&quot;, line 11, in predict\\n    with open(\\'./model_files/model.bin\\', \\'rb\\') as f_in:\\nFileNotFoundError: [Errno 2] No such file or directory: \\'./model_files/model.bin\\'</textarea>\\n  </form>\\n</div>\\n<div class=\"explanation\">\\n  The debugger caught an exception in your WSGI application.  You can now\\n  look at the traceback which led to the error.  <span class=\"nojavascript\">\\n  If you enable JavaScript you can also use additional features such as code\\n  execution (if the evalex feature is enabled), automatic pasting of the\\n  exceptions and much more.</span>\\n</div>\\n      <div class=\"footer\">\\n        Brought to you by <strong class=\"arthur\">DON\\'T PANIC</strong>, your\\n        friendly Werkzeug powered traceback interpreter.\\n      </div>\\n    </div>\\n\\n    <div class=\"pin-prompt\">\\n      <div class=\"inner\">\\n        <h3>Console Locked</h3>\\n        <p>\\n          The console is locked and needs to be unlocked by entering the PIN.\\n          You can find the PIN printed out on the standard output of your\\n          shell that runs the server.\\n        <form>\\n          <p>PIN:\\n            <input type=text name=pin size=14>\\n            <input type=submit name=btn value=\"Confirm Pin\">\\n        </form>\\n      </div>\\n    </div>\\n  </body>\\n</html>\\n\\n<!--\\n\\nTraceback (most recent call last):\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 2464, in __call__\\n    return self.wsgi_app(environ, start_response)\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 2450, in wsgi_app\\n    response = self.handle_exception(e)\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 1867, in handle_exception\\n    reraise(exc_type, exc_value, tb)\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\_compat.py\", line 39, in reraise\\n    raise value\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 2447, in wsgi_app\\n    response = self.full_dispatch_request()\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 1952, in full_dispatch_request\\n    rv = self.handle_user_exception(e)\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 1821, in handle_user_exception\\n    reraise(exc_type, exc_value, tb)\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\_compat.py\", line 39, in reraise\\n    raise value\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 1950, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\Lib\\\\site-packages\\\\flask\\\\app.py\", line 1936, in dispatch_request\\n    return self.view_functions[rule.endpoint](**req.view_args)\\n  File \"C:\\\\1.VIVIANA\\\\DATA_SCIENCE\\\\Proyectos_mlearning\\\\AutoMpg\\\\ml_flask_app\\\\flask_env\\\\main.py\", line 11, in predict\\n    with open(\\'./model_files/model.bin\\', \\'rb\\') as f_in:\\nFileNotFoundError: [Errno 2] No such file or directory: \\'./model_files/model.bin\\'\\n\\n-->'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:9696/\"  #\"http://0.0.0.0:9696/\" \n",
    "r = requests.post(url, json = vehicle_config)\n",
    "r.text.strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
